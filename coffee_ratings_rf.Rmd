---
title: "coffee-ratings-rf"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
require(tidyverse)
require(tidytuesdayR)

# last_tuesday <- lubridate::floor_date(Sys.Date(), "week", week_start = 2)

my_tuesday <- "2020-07-07"

cr <- tidytuesdayR::tt_load(my_tuesday)

cr <- cr$coffee_ratings
```

```{r}

# seems somewhat normal
cr %>% 
  ggplot(aes(cupper_points)) +
  geom_histogram(bins = 100)
```

## prelimenary modeling

```{r}
require(broom)

lm1 <- cr %>%
  mutate(country_of_origin = fct_lump(country_of_origin, 4)) %>% 
  lm(cupper_points ~ number_of_bags + country_of_origin + total_cup_points + altitude_mean_meters, data = .) %>% 
  tidy(conf.int = TRUE)
  
lm1 %>% 
  filter(term != "(Intercept)") %>% 
  arrange(estimate) %>% 
  filter(p.value <= .05) %>% 
  ggplot(aes(estimate, term)) +
  geom_point() +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high))
```

## random forest to predict cupper_points

```{r}
require(tidymodels)

cr <- cr %>% 
  mutate_if(is.character, factor)

set.seed(321)
isplit <- initial_split(cr)

train_df <- training(isplit)
test_df <- testing(isplit)

xgb_spec <- boost_tree(
  trees = 1000,
  tree_depth = tune(),
  min_n = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  mtry = tune(),
  learn_rate = tune()
) %>% 
  set_engine("xgboost") %>% 
  set_mode("regression")

xgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), train_df),
  learn_rate(),
  size = 30
)
```

we had to treat `mtry()` differently because it depends on the actual number of predictors in the data.

```{r}
wf <- workflow() %>% 
  add_formula(cupper_points ~.) %>% 
  add_model(xgb_spec)
```

let's create cross-validation resamples for tuning our model.

```{r}
set.seed(432)
coffolds <- vfold_cv(train_df)
```

```{r}
require(tidyverse)
require(tidymodels)
doParallel::registerDoParallel()

set.seed(543)

xgb_res <- tune_grid(
  wf,
  resamples = coffolds,
  grid = xgb_grid,
  control = control_grid(save_pred = TRUE)
)

```

```{r}
collect_metrics(xgb_res)
```

```{r}
xgb_res %>%
  collect_metrics() %>%
  filter(.metric == "rsq") %>% 
  select(mtry:sample_size) %>% 
  pivot_longer(mtry:sample_size,
               values_to = "value",
               names_to = "parameter") %>% 
  ggplot(aes(value, fill = parameter)) +
  geom_histogram() +
  facet_wrap(~parameter, scale = "free")
```

```{r}
show_best(xgb_res, "rsq")
```

```{r}
best_rsq <- select_best(xgb_res, "rsq")
best_rsq
```

```{r}
final_xgb <- finalize_workflow(
  wf,
  best_rsq
)

final_xgb
```

Instead of `tune()` placeholders, we now have real values for all the model hyperparameters.

```{r}
library(vip)

final_xgb %>%
  fit(data = train_df) %>%
  pull_workflow_fit() %>%
  vip(geom = "point")
```

```{r}
final_res <- last_fit(final_xgb, isplit)
```

```{r}
final_res %>% 
  collect_predictions() %>% 
  ggplot(aes(.row, .pred)) +
  geom_point(color = "blue") +
  geom_point(aes(.row, cupper_points), color = "red") +
  labs(y = "cupper_points",
       x = "row id",
       title = "Cupper points predictions",
       subtitle = "blue = predictions, red = actuals")
```

```{r}
my_fit <- final_xgb %>%
  fit(data = train_df) %>%
  pull_workflow_fit()
```

```{r}
my_fit <- final_xgb %>% 
  fit(train_df)

# see predictions of model fit on first 25 obs from test_df
my_fit %>% 
  predict(test_df[1:25,]) %>% 
  bind_cols(test_df[1:25,]) %>% 
  select(cupper_points, .pred, everything())

# should be able to predict using final_res, which is trained on resamples

```

