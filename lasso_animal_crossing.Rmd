---
title: "animal-crossing"
output: html_document
---

https://www.youtube.com/watch?v=Xt7ACiedRRI

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
require(tidyverse)
theme_set(theme_light())

# Get the Data

critic <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/critic.tsv')
user_reviews <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/user_reviews.tsv')
items <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/items.csv')
villagers <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv')
```

```{r}
villagers
items
```

```{r}
require(tidytext)
require(widyr)
require(stm)

user_review_words <- user_reviews %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words, by = "word") %>% 
  count(user_name, date, grade, word)

review_matrix <- user_review_words %>% 
  group_by(word) %>% 
  filter(n() >= 25) %>% 
  cast_sparse(user_name, word, n)

topic_model <- stm(review_matrix, 
                   K = 6, 
                   verbose = FALSE, 
                   init.type = "Spectral",
                   emtol = 5e-5)

tidy(topic_model) %>% 
  group_by(topic) %>% 
  top_n(12, beta) %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(beta, term)) +
  geom_col() +
  scale_y_reordered() +
  facet_wrap(~topic, scales = "free_y")

## left off at -18:42

```


## switch to Julia Silge's animal crossing text analysis video with same data
 
```{r}
user_reviews %>% 
  filter(grade > 8) %>% 
  sample_n(5) %>% 
  pull(text)
```
 
```{r}
reviews_parsed <- user_reviews %>% 
  mutate(text = str_remove(text, "Expand$"),
         rating = case_when(grade > 6 ~ "good",
                            TRUE ~ "bad"))

reviews_parsed
```

```{r}
library(tidytext)

words_per_review <- reviews_parsed %>% 
  unnest_tokens(word, text) %>% 
  count(user_name, name = "total_words")

# very weirds distribution, fix in data
words_per_review %>% 
  ggplot(aes(total_words)) +
  geom_histogram()
```



## Build a model

```{r}
library(tidymodels)

set.seed(4327901)

review_split <- initial_split(reviews_parsed, strata = "rating")

review_train <- training(review_split)
review_test <- testing(review_split)

```

```{r}
library(textrecipes)

review_rec <- recipe(rating ~ text, data = review_train) %>% 
  step_tokenize(text) %>% 
  step_stopwords(text) %>% 
  step_tokenfilter(text, max_tokens = 500) %>%   # filter heavily so model runs quickly
  step_tfidf(text) %>% 
  # center and scale all predictors after converting to tf_idf
  step_normalize(all_predictors())

review_prep <- prep(review_rec)

```

```{r}
# declare model specification

lasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%   # lasso model
  set_engine("glmnet")

lasso_wf <- workflow() %>% 
  add_recipe(review_rec) %>% 
  add_model(lasso_spec)

lasso_wf

```


## tune model parameters

```{r}
lambda_grid <- grid_regular(penalty(), levels = 30)

set.seed(1230784)
review_folds <- bootstraps(review_train, strata = rating)
review_folds
```

```{r}
doParallel::registerDoParallel()

set.seed(2020)

lasso_grid <- tune_grid(
  lasso_wf,
  resamples = review_folds,
  grid = lambda_grid,
  metrics = metric_set(roc_auc, ppv, npv)
)
```


```{r}
lasso_grid %>% 
  collect_metrics()

lasso_grid %>% 
  collect_metrics() %>% 
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_line(size = 1.5, show.legend = FALSE) +
  facet_wrap(~.metric) +
  scale_x_log10()

# auc: best model by auc is peak auc
```



## choose final model

```{r}
best_auc <- lasso_grid %>% 
  select_best("roc_auc")

best_auc

final_lasso <- finalize_workflow(lasso_wf, best_auc)

final_lasso
```

```{r}
library(vip)

# fit and get importance for all tokens
fit_vars <- final_lasso %>% 
  fit(review_train) %>% 
  pull_workflow_fit() %>% 
  vi(lambda = best_auc$penalty)

# compare variable importance for NEG vs POS reviews
fit_vars %>% 
  group_by(Sign) %>% 
  top_n(20, wt = abs(Importance)) %>% 
  ungroup() %>% 
  mutate(Importance = abs(Importance),
         Variable = str_remove(Variable, "tfidf_text_"),
         Variable = fct_reorder(Variable, Importance)) %>% 
  ggplot(aes(Importance, Variable, fill = Sign)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Sign, scales = "free_y")
```


```{r}
# fits to training data and evaluates on test data
review_final <- last_fit(final_lasso, review_split)

review_final %>% 
  collect_metrics()

review_final %>% 
  collect_predictions()

review_final %>% 
  collect_predictions() %>% 
  conf_mat(rating, .pred_class)
```










